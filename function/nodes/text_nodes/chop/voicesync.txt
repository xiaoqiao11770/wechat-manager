#type: node
#context: chop
#internal: voicesync
#icon: CHOP/voicesync

= Voice Sync =

"""The Voice Sync CHOP detects phonemes in an audio channel given some
audio phoneme samples and pro..."""

The Voice Sync CHOP detects phonemes in an audio channel given some
audio phoneme samples and produces lip control channels.

In order to set up a lip-synching system based on phoneme detection, you
need to model different mouth shapes for each viseme (visually similar
phonemes) and create a "phoneme library" of sample phonemes. 

Once these
steps are complete, the Voice Sync CHOP matches the phoneme library to
the audio voice track in input 1. The Voice Sync CHOP outputs a channel
for each phoneme (or viseme). Each channel contains the occurrences of
the phoneme in the voice track (as `1` when detected, `0` otherwise)
over its full length.


@parameters

    == Voice Sync ==

        Quality:
            Allows you to trade off between performance and accuracy.
        Silence Level:
            Voice Detection will only be performed on the input audio if
            its average volume for a given segment is higher than this
            value. It should be adjusted so that background noise is not
            interpreted as voice.
        Silence Chan Name:
            Creates a channel which acts as a 'silence phoneme'.
        Vocal Range (Hz):
            The approximate vocal range of the voice actor. The defaults
            are for an average male speaker. This parameter is only used
            by Voiced Phonemes.
        Max Pitch Shift:
            The maximum number of octaves that a phoneme in the voice
            track can differ in pitch from the sample phoneme.
        Noise Filter (Hz):
            Controls the size of the the noise filter to smooth out
            non-voiced phonemes.
        Setup Phoneme Library:
            This button build the phoneme library from the second and
            third inputs. It is only used in time slice mode. Before
            starting the realtime synching, initialize the phoneme
            library by clicking this button.

    == Output ==

        Convert Scores into On/Off States:
            Produces binary on/off state channels for each viseme into
            On/Off States rather than outputing the raw scores.
        Minimum Score:
            The viseme with the highest score is chosen to be the match.
            However, if its score is not above the minimum score, then
            no visemes will be chosen. This parameter helps to eliminate
            poor matches.
        Voiced Bias:
            Voiced and Non-Voiced phonemes are detected using the
            different methods. If you find that either the Voiced or
            Non-Voiced phonemes are dominating the output, you can shift
            the bias to balance them. Zero bias doesn't favor either
            method, +1 completely favors Voiced phonemes and -1
            completely favors Non-Voiced phonemes. Normally values
            should remain close to zero.
        Sample Rate:
            The sample rate of the output channels. This allow partially
            determines how many matches are done on the input audio.
        Super Sample:
            How many comparisons are done per output sample. A higher
            super sample will increase the matching accuracy, but will
            affect performance greatly.
            
    [Include:common]

@related
    - [Node:chop/phoneme]
    - [Node:chop/voicesplit]

